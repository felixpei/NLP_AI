{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6HbiNb7tuPNW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from gensim.models import word2vec\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlAf6k8euPNa"
   },
   "source": [
    "### Step 0. Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvEhxA7_uPNb"
   },
   "source": [
    "#### Step 0.1 load article cutted and article df and define y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EZwp-WsZuPNb"
   },
   "outputs": [],
   "source": [
    "with open(\"../article_cutted\", \"rb\") as file:\n",
    "    docs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bFQvhCnouPNd"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/article_preprocessed.csv')\n",
    "diff_threshold = 20\n",
    "df = df[abs(df['push']-df['boo']) > diff_threshold].copy()\n",
    "df['type'] = np.clip(df['push']-df['boo'], 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8XHk6SguPNg"
   },
   "source": [
    "#### Step 0.2 create word id mapping and word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "N0evuFZJuPNg"
   },
   "outputs": [],
   "source": [
    "w2v = word2vec.Word2Vec.load('../word2vec_model/CBOW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TTqL7HAPuPNi"
   },
   "outputs": [],
   "source": [
    "word2id = {k:i for i, k in enumerate(w2v.wv.vocab.keys())}\n",
    "id2word = {i:k for k, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "crdG_vUmuPNk"
   },
   "outputs": [],
   "source": [
    "words_len = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NBJ8KKsiuPNn"
   },
   "outputs": [],
   "source": [
    "embedding = np.zeros((words_len+1, 256))\n",
    "for k, v in word2id.items():\n",
    "    embedding[v] = w2v.wv[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ww_Yjk2auPNp"
   },
   "source": [
    "#### Step 0.3 sentence to seq transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bKE_MSpIuPNq"
   },
   "outputs": [],
   "source": [
    "input_length = 80\n",
    "docs_id = []\n",
    "for doc in docs:\n",
    "    text = doc[:input_length]\n",
    "    ids = [words_len+1]*input_length\n",
    "    ids[:len(text)] = [word2id[w] if w in word2id else words_len+1 for w in text]\n",
    "\n",
    "    docs_id.append(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Z9vZqbvGuPNr",
    "outputId": "9995fffd-ce85-4c8e-822f-771fbf8b40fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['韓瑜', '協志', '前妻', '正', '女演員', '周子', '瑜', 'TWICE', '團裡裡面', '台灣', '人', '正', '兩個', '要當', '鄉民', '老婆', '選', '五樓', '真', '勇氣']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 100035, 8, 9, 3, 10, 11, 12, 13, 14, 15, 16, 17, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035, 100035]\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])\n",
    "print(docs_id[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QIgXcRXDuPNv"
   },
   "source": [
    "### Step 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nz_CRjP1uPNw"
   },
   "source": [
    "#### Step 1.1 Creating Training and Testing sets and creating generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eVjfzGNDuPNx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7n4Lfma2uPN0"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, shuffle=True, stratify=df['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3QCQnnIhuPN2"
   },
   "outputs": [],
   "source": [
    "def train_data_generator(df, bz, docs_id):\n",
    "    # bz: batch size \n",
    "    \n",
    "    dfs = [sub_df for key,sub_df in df.groupby('type')]\n",
    "    df_n = len(dfs)\n",
    "    \n",
    "    docs_id = np.array(docs_id)\n",
    "    while True:\n",
    "        selected = pd.concat([sub_df.sample(int(bz/2)) for sub_df in dfs], axis=0)\n",
    "        selected = selected.sample(frac=1)\n",
    "        x = docs_id[selected['idx']]\n",
    "        y = selected.as_matrix(columns=['type'])\n",
    "                    \n",
    "        yield x, y\n",
    "        \n",
    "def test_data_generator(df, docs_id):\n",
    "    docs_id = np.array(docs_id)\n",
    "    x = docs_id[df['idx']]\n",
    "    y = df.as_matrix(columns=['type'])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iOwTLmDkuPN4"
   },
   "outputs": [],
   "source": [
    "X_test, Y_test = test_data_generator(test, docs_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1j599yZuPN6"
   },
   "source": [
    "### Let's create the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eib4FB-CuPN7"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "update_per_epochs = 100\n",
    "\n",
    "learning_rate=0.001\n",
    "hidden_layer_size=64\n",
    "number_of_layers=1\n",
    "dropout=True\n",
    "dropout_rate=0.8\n",
    "number_of_classes=1\n",
    "gradient_clip_margin=4\n",
    "wv=embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GHIAFkXduPN9"
   },
   "outputs": [],
   "source": [
    "def LSTM_cell(hidden_layer_size, batch_size, number_of_layers, dropout=True, dropout_rate=0.8):\n",
    "    def get_LSTM(hidden_layer_size, dropout, dropout_rate):\n",
    "        layer = tf.contrib.rnn.BasicLSTMCell(hidden_layer_size)\n",
    "\n",
    "        if dropout:\n",
    "            layer = tf.contrib.rnn.DropoutWrapper(layer, output_keep_prob=dropout_rate)\n",
    "            \n",
    "        return layer\n",
    "    \n",
    "    cell = tf.contrib.rnn.MultiRNNCell([get_LSTM(hidden_layer_size, dropout, dropout_rate) for _ in range(number_of_layers)])\n",
    "\n",
    "    init_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    return cell, init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wfl64n1GuPOA"
   },
   "outputs": [],
   "source": [
    "def output_layer(lstm_output, out_size):\n",
    "    x = lstm_output[:, -1, :]\n",
    "    output = tf.layers.dense(inputs= x, units= out_size, activation = tf.nn.sigmoid)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "c497NKMBuPOC"
   },
   "outputs": [],
   "source": [
    "def opt_loss(logits, targets, learning_rate, grad_clip_margin):\n",
    "    \n",
    "    loss = tf.reduce_sum(tf.pow(logits - targets, 2))/batch_size\n",
    "    \n",
    "    #Cliping the gradient loss\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    gradients = optimizer.compute_gradients(loss)\n",
    "\n",
    "    capped_gradients = [(tf.clip_by_value(grad, (-1)*grad_clip_margin, grad_clip_margin), var) for grad, var in gradients if grad is not None]\n",
    "    \n",
    "    train_optimizer = optimizer.apply_gradients(capped_gradients)\n",
    "\n",
    "    \n",
    "    return loss, train_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VRWsII5cuPOD"
   },
   "outputs": [],
   "source": [
    "main_graph = tf.Graph()\n",
    "sess = tf.Session(graph=main_graph)\n",
    "\n",
    "with main_graph.as_default():\n",
    "    \n",
    "    ##defining placeholders##\n",
    "    with tf.name_scope('input'):\n",
    "        inputs = tf.placeholder(tf.int32, [None, input_length], name='input_data')\n",
    "        targets = tf.placeholder(tf.float32, [None, 1], name='targets')\n",
    "        bz = tf.placeholder(tf.int32, [], name='batch_size')\n",
    "        \n",
    "    ## embedding lookup table\n",
    "    with tf.variable_scope('embedding'):    \n",
    "        em_W = tf.Variable(wv.astype(np.float32), trainable=True)  #wv.shape = (100035, 256)\n",
    "        x = tf.nn.embedding_lookup(em_W, inputs)    #x.shape = (?, 80, 256)\n",
    "        \n",
    "    ##LSTM layer##\n",
    "    with tf.variable_scope(\"LSTM_layer\"):\n",
    "        cell, init_state = LSTM_cell(hidden_layer_size, tf.shape(inputs)[0], number_of_layers, dropout, dropout_rate) \n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, x, initial_state=init_state)\n",
    "    \n",
    "    ##Output layer##   \n",
    "    with tf.variable_scope('output_layer'):\n",
    "        logits = output_layer(outputs, number_of_classes)\n",
    "    \n",
    "    ##loss and optimization##\n",
    "    with tf.name_scope('loss_and_opt'):\n",
    "        loss, opt = opt_loss(logits, targets, learning_rate, gradient_clip_margin)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-vsxfy3uPOF"
   },
   "source": [
    "### Time to train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DoQJCDVYuPOF"
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fPnPG66kuPOH"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "train_generate = train_data_generator(train, batch_size, docs_id)\n",
    "\n",
    "train_loss = []\n",
    "train_auc = []\n",
    "test_loss = []\n",
    "test_auc = []\n",
    "for i in range(epochs):\n",
    "    traind_scores = []\n",
    "    epoch_loss = []\n",
    "    for j in range(update_per_epochs):\n",
    "        X_batch, y_batch = next(train_generate) \n",
    "        \n",
    "        o, c, _ = sess.run([logits, loss, opt], feed_dict={\n",
    "            inputs:X_batch, \n",
    "            targets:y_batch,\n",
    "            bz:np.array(batch_size)\n",
    "        })\n",
    "        \n",
    "        epoch_loss.append(c)\n",
    "        traind_scores.append(roc_auc_score(y_batch, o))\n",
    "    \n",
    "    to, tc = sess.run([logits, loss], feed_dict={\n",
    "        inputs:X_test, \n",
    "        targets:Y_test,\n",
    "        bz:np.array(len(X_test))\n",
    "    })\n",
    "    \n",
    "    train_loss.append(np.mean(epoch_loss))\n",
    "    train_auc.append(np.mean(traind_scores))\n",
    "    test_loss.append(tc)\n",
    "    test_auc.append(roc_auc_score(Y_test, to))\n",
    "    \n",
    "    if (i % 5) == 0:\n",
    "        print('Epoch {}/{}'.format(i, epochs), ' Train loss: {}'.format(np.mean(epoch_loss)), \n",
    "              ' Train auc: {}'.format(np.mean(traind_scores)), \n",
    "             ' Test loss: {}'.format(tc), ' Test auc: {}'.format(roc_auc_score(Y_test, to)))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "07_rnn_ptt_text_classification.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
